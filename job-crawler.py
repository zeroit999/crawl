import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time

def get_region_links():
    """Láº¥y 3 link chÃ­nh cá»§a cÃ¡c vÃ¹ng miá»n"""
    main_url = "https://tuyensinhso.vn/diem-chuan.html"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        print("ğŸ”„ Äang káº¿t ná»‘i Ä‘áº¿n trang chÃ­nh...")
        response = requests.get(main_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        region_links = []
        
        # TÃ¬m táº¥t cáº£ cÃ¡c link cÃ³ chá»©a tá»« khÃ³a vÃ¹ng miá»n
        for a in soup.find_all('a', href=True):
            href = a['href']
            text = a.get_text(strip=True)
            
            if any(keyword in href for keyword in ['mien-bac', 'mien-trung', 'mien-nam']):
                full_url = urljoin(main_url, href)
                if full_url not in region_links:
                    region_links.append(full_url)
        
        # Sáº¯p xáº¿p theo thá»© tá»±: Báº¯c, Trung, Nam
        sorted_links = []
        for region in ['mien-bac', 'mien-trung', 'mien-nam']:
            for link in region_links:
                if region in link:
                    sorted_links.append(link)
                    break
        
        return sorted_links[:3]  # Chá»‰ láº¥y 3 link Ä‘áº§u tiÃªn
        
    except Exception as e:
        print(f"âŒ Lá»—i khi láº¥y link vÃ¹ng miá»n: {e}")
        # Tráº£ vá» cÃ¡c link máº·c Ä‘á»‹nh náº¿u khÃ´ng crawl Ä‘Æ°á»£c
        return [
            "https://tuyensinhso.vn/diem-chuan/diem-chuan-cac-truong-dai-hoc-hoc-vien-khu-vuc-mien-bac-c47979.html",
            "https://tuyensinhso.vn/diem-chuan/diem-chuan-cac-truong-dai-hoc-hoc-vien-khu-vuc-mien-trung-c48009.html",
            "https://tuyensinhso.vn/diem-chuan/diem-chuan-cac-truong-dai-hoc-hoc-vien-khu-vuc-mien-nam-c47986.html"
        ]

def get_university_links(region_url, region_name):
    """Láº¥y danh sÃ¡ch cÃ¡c link trÆ°á»ng Ä‘áº¡i há»c tá»« trang vÃ¹ng miá»n"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        print(f"ğŸ”„ Äang truy cáº­p {region_name}...")
        response = requests.get(region_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        university_links = []
        
        # TÃ¬m táº¥t cáº£ cÃ¡c link trÆ°á»ng Ä‘áº¡i há»c - phÆ°Æ¡ng phÃ¡p tá»•ng quÃ¡t
        for a in soup.find_all('a', href=True):
            href = a['href']
            text = a.get_text(strip=True)
            
            # Lá»c cÃ¡c link cÃ³ chá»©a 'diem-chuan' vÃ  khÃ´ng chá»©a 'khu-vuc'
            if ('diem-chuan' in href and 
                'khu-vuc' not in href and
                not href.startswith('#')):
                
                full_url = urljoin(region_url, href)
                if full_url not in university_links:
                    university_links.append(full_url)
        
        # Náº¿u khÃ´ng tÃ¬m tháº¥y link nÃ o, thá»­ phÆ°Æ¡ng phÃ¡p khÃ¡c
        if not university_links:
            # TÃ¬m theo class hoáº·c structure thÃ´ng thÆ°á»ng
            for item in soup.find_all(['li', 'div', 'tr']):
                links = item.find_all('a', href=True)
                for a in links:
                    href = a['href']
                    if 'diem-chuan' in href and 'khu-vuc' not in href:
                        full_url = urljoin(region_url, href)
                        if full_url not in university_links:
                            university_links.append(full_url)
        
        return university_links
        
    except Exception as e:
        print(f"âŒ Lá»—i khi láº¥y link trÆ°á»ng tá»« {region_name}: {e}")
        return []

def main():
    print("ğŸš€ Báº¯t Ä‘áº§u crawl dá»¯ liá»‡u tá»« tuyensinhso.vn")
    print("=" * 70)
    
    # Láº¥y 3 link vÃ¹ng miá»n
    region_links = get_region_links()
    
    if not region_links:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y link vÃ¹ng miá»n")
        return
    
    region_names = {
        'mien-bac': 'Miá»n Báº¯c',
        'mien-trung': 'Miá»n Trung', 
        'mien-nam': 'Miá»n Nam'
    }
    
    all_university_links = []
    
    # Duyá»‡t qua tá»«ng vÃ¹ng miá»n
    for region_url in region_links:
        region_key = None
        for key in region_names.keys():
            if key in region_url:
                region_key = key
                break
        
        if region_key:
            region_name = region_names[region_key]
            university_links = get_university_links(region_url, region_name)
            
            print(f"\nğŸ“‹ {region_name.upper()} - {len(university_links)} trÆ°á»ng:")
            print("-" * 70)
            
            for i, link in enumerate(university_links, 1):
                print(f"{i:2d}. {link}")
                all_university_links.append(link)
            
            # Dá»«ng 2 giÃ¢y giá»¯a cÃ¡c request
            time.sleep(2)
        else:
            print(f"âš ï¸ KhÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c vÃ¹ng miá»n tá»« URL: {region_url}")
    
    print("\n" + "=" * 70)
    print(f"âœ… Tá»•ng sá»‘ link trÆ°á»ng Ä‘áº¡i há»c: {len(all_university_links)}")
    print("=" * 70)

if __name__ == "__main__":
    main()